## å¯å¤çŽ°çš„

### Minuet: Accelerating 3D Sparse Convolutions on GPUs

ç¨€ç–å·ç§¯ (SC) å¹¿æ³›åº”ç”¨äºŽæœ¬è´¨ä¸Šé«˜åº¦ç¨€ç–çš„ 3D ç‚¹äº‘ç½‘ç»œã€‚çŽ°æœ‰çš„ SC å‘åŠ¨æœºå­˜åœ¨ä¸‰ä¸ªç¼ºç‚¹ã€‚é¦–å…ˆï¼Œå®ƒä»¬ä¾é å“ˆå¸Œè¡¨æ¥æå–å¿…è¦çš„é€šç”¨çŸ©é˜µä¹˜æ³• (GEMM) è¿ç®—ï¼Œä»Žè€Œå¯¼è‡´é€šè¿‡æ˜‚è´µçš„ GPU å…¨å±€å†…å­˜è¿›è¡Œä¸è§„åˆ™çš„æ•°æ®è®¿é—®ã€‚å…¶æ¬¡ï¼Œå®ƒä»¬é‡‡ç”¨å•ä¸ªå›ºå®šçš„å›¾å—å¤§å°æ¥å¤„ç†å¤šä¸ªè¾“å…¥/è¾“å‡ºç‰¹å¾é€šé“ï¼Œè¿™å¹¶ä¸æ€»æ˜¯èƒ½å¤Ÿåœ¨å„ä¸ªå±‚ã€è¾“å…¥æ•°æ®é›†å’Œ GPU æž¶æž„ä¸Šæä¾›æœ€ä½³æ€§èƒ½ã€‚ç¬¬ä¸‰ï¼Œå®ƒä»¬å¡«å……é›¶æ•°æ®ï¼Œå¹¶å°†å¤šä¸ª GEMM æ“ä½œåˆ†ç»„ä¸ºéµå¾ªæƒé‡åç§»æŽ’åºçš„å•ä¸ªå†…æ ¸å¯åŠ¨ã€‚è¿™ç§åˆ†ç»„æ–¹æ¡ˆä¼šå¯¼è‡´è®¸å¤šå†—ä½™æ•°æ®è®¿é—®å’Œå¯¹æ— ç”¨ï¼ˆé›¶ï¼‰æ•°æ®çš„è®¡ç®—ã€‚

ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº† Minuetï¼Œè¿™æ˜¯ä¸€ç§ä¸“ä¸ºçŽ°ä»£ GPU é‡èº«å®šåˆ¶çš„æ–°åž‹å†…å­˜é«˜æ•ˆ SC å¼•æ“Žã€‚Minuet å¼•å…¥äº† (i) åˆ†æ®µæŽ’åºåŒéåŽ†äºŒåˆ†æœç´¢ç®—æ³•ï¼Œè¯¥ç®—æ³•åœ¨æå–å·ç§¯æ‰€éœ€çš„ GEMM æ“ä½œæ—¶å……åˆ†åˆ©ç”¨ GPU ç‰‡ä¸Šå†…å­˜å±‚æ¬¡ç»“æž„çš„æ‰€æœ‰çº§åˆ«ï¼Œ(ii) ä¸€ç§è½»é‡çº§è‡ªåŠ¨è°ƒæ•´æ–¹æ¡ˆï¼Œå¯åœ¨ä»¥ä¸‹æƒ…å†µä¸‹é…ç½®å›¾å—å¤§å°ï¼šå¤„ç†å¤šä¸ªé€šé“ï¼Œä»Žè€Œä½¿ SC æ‰§è¡Œé€‚åº”æ¯ä¸€å±‚ã€æ•°æ®é›†å’Œ GPU æž¶æž„çš„ç‰¹å¾ï¼Œä»¥åŠ (iii) å¡«å……é«˜æ•ˆçš„ GEMM åˆ†ç»„æ–¹æ³•ï¼Œå¯å‡å°‘å¡«å……æˆæœ¬å’Œå†—ä½™ï¼ˆé›¶ï¼‰æ•°æ®è®¿é—®å’Œè®¡ç®—ã€‚æˆ‘ä»¬çš„è¯„ä¼°è¡¨æ˜Žï¼ŒMinuet çš„å¹³å‡æ€§èƒ½æ˜Žæ˜¾ä¼˜äºŽä¹‹å‰æœ€å…ˆè¿›çš„ SC å‘åŠ¨æœº1.74Ã—1.74 Ã—ï¼ˆå–å†³äºŽ2.22Ã—2.22 Ã—ï¼‰ç”¨äºŽç«¯åˆ°ç«¯ç‚¹äº‘ç½‘ç»œæ‰§è¡Œã€‚æˆ‘ä»¬æ–°é¢–çš„åˆ†æ®µæŽ’åºåŒéåŽ†äºŒåˆ†æœç´¢ç®—æ³•é€šè¿‡ä»¥ä¸‹æ–¹å¼å®žçŽ°äº†å“è¶Šçš„åŠ é€Ÿ15.8Ã—15.8 Ã—å¹³å‡ï¼ˆæœ€å¤š26.8Ã—26.8 Ã—ï¼‰è¶…è¿‡äº†ä¹‹å‰æœ€å…ˆè¿›çš„ä½œå“ã€‚

### SplitFTï¼šé€šè¿‡è¿œç¨‹å†…å­˜è®°å½•å®žçŽ°åˆ†ç±»æ•°æ®ä¸­å¿ƒçš„å®¹é”™

æˆ‘ä»¬æŽ¨å‡º SPLITFTï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„å®¹é”™æ–¹æ³•ï¼Œé€‚ç”¨äºŽåˆ†ç±»æ•°æ®ä¸­å¿ƒä¸­ä»¥å­˜å‚¨ä¸ºä¸­å¿ƒçš„åº”ç”¨ç¨‹åºã€‚SPLITFT ä½¿ç”¨æ–°é¢–çš„æ‹†åˆ†æž¶æž„ï¼Œå…¶ä¸­å¤§å†™æ“ä½œç›´æŽ¥åœ¨åº•å±‚åˆ†è§£æ–‡ä»¶ç³»ç»Ÿä¸Šæ‰§è¡Œï¼Œè€Œå°å†™æ“ä½œåˆ™åœ¨è®¡ç®—å±‚å†…è¿›è¡Œå®¹é”™ã€‚åˆ†ä½“å¼æž¶æž„ä½¿åº”ç”¨ç¨‹åºèƒ½å¤Ÿåœ¨ä¸å½±å“æ€§èƒ½çš„æƒ…å†µä¸‹èŽ·å¾—å¼ºå¤§çš„è€ç”¨æ€§ä¿è¯ã€‚SPLITFT ä½¿ç”¨ä¸€ç§ç§°ä¸ºè¿‘è®¡ç®—æ—¥å¿— (NCL) çš„æ–°æŠ½è±¡ï¼Œä»¥å¿«é€Ÿã€å»‰ä»·ä¸”é€æ˜Žçš„æ–¹å¼ä½¿å°å†™å…¥å…·æœ‰å®¹é”™èƒ½åŠ›ã€‚æˆ‘ä»¬å°†ä¸‰ä¸ª POSIX åº”ç”¨ç¨‹åºï¼ˆRocksDBã€Redis å’Œ SQLiteï¼‰ç§»æ¤åˆ° SPLITFTï¼Œå¹¶è¯æ˜Žä¸Žå¯èƒ½ä¸¢å¤±æ•°æ®çš„å¼±ç‰ˆæœ¬åº”ç”¨ç¨‹åºç›¸æ¯”ï¼Œå®ƒä»¬æä¾›äº†å¼ºæœ‰åŠ›çš„ä¿è¯ï¼›SPLITFT åº”ç”¨ç¨‹åºè¿™æ ·åšï¼ŒåŒæ—¶è¿‘ä¼¼å¼±ç‰ˆæœ¬çš„æ€§èƒ½ï¼ˆåœ¨ YCSB ä¸‹ä»…äº§ç”Ÿ 0.1%-10% çš„å¼€é”€ï¼‰ã€‚ä¸Žå¼ºç‰ˆæœ¬ç›¸æ¯”ï¼ŒSPLITFT æ˜¾ç€æé«˜äº†æ€§èƒ½ï¼ˆåœ¨å†™å…¥ç¹é‡çš„å·¥ä½œè´Ÿè½½ä¸‹å¤§çº¦æé«˜äº† 2.5 å€åˆ° 27 å€ï¼‰ã€‚

### Orionï¼šé’ˆå¯¹ ML åº”ç”¨ç¨‹åºçš„å¹²æ‰°æ„ŸçŸ¥ã€ç»†ç²’åº¦ GPU å…±äº«

https://github.com/eth-easl/orion

GPU å¯¹äºŽæœ€å¤§åŒ–æ·±åº¦ç¥žç»ç½‘ç»œ (DNN) åº”ç”¨çš„æ¯ç“¦åžåé‡è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå³ä½¿ä½¿ç”¨å¤§æ‰¹é‡å¤§å°å¹¶æ¶ˆé™¤ä»»ä½•è¾“å…¥æ•°æ®å¤„ç†æˆ–é€šä¿¡åœé¡¿ï¼ŒDNN åº”ç”¨ç¨‹åºé€šå¸¸ä¹Ÿæ— æ³•å……åˆ†åˆ©ç”¨æ˜‚è´µçš„ GPU èµ„æºã€‚æ ¹æœ¬åŽŸå› æ˜¯ DNN å·¥ä½œè´Ÿè½½ç”±è®¸å¤šä¾èµ–äºŽæ•°æ®çš„è¿ç®—ç¬¦ç»„æˆï¼Œæ¯ä¸ªè¿ç®—ç¬¦æ‰§è¡Œ 10 åˆ° 1000 ä¸ª ðœ‡ï¼Œè®¡ç®—å’Œå†…å­˜è¦æ±‚æˆªç„¶ä¸åŒã€‚ ( gnn å¹¶æ²¡æœ‰è¿™ä¹ˆå¤šè¿ç®—ç¬¦, ä¸»è¦æ˜¯åœ¨æ•°æ®åŠ è½½çš„è¿‡ç¨‹ä¸­. )

è™½ç„¶æ“ä½œå‘˜å¯èƒ½ä¼šä½¿ GPU è®¡ç®—å•å…ƒæˆ–å†…å­˜å¸¦å®½é¥±å’Œï¼Œä½†å®ƒé€šå¸¸ä¼šä½¿å…¶ä»– GPU èµ„æºé—²ç½®ã€‚å°½ç®¡ GPU å…±äº«æŠ€æœ¯å¾ˆæµè¡Œï¼Œä½†å½“å‰çš„æ–¹æ³•è¿˜ä¸å¤Ÿç»†ç²’åº¦æˆ–å¹²æ‰°æ„ŸçŸ¥ï¼Œæ— æ³•æœ€å¤§é™åº¦åœ°æé«˜ GPU åˆ©ç”¨çŽ‡ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°å‡å°‘ DNN åº”ç”¨æ‰€éœ€çš„ 10 ðœ‡ ç²’åº¦çš„å¹²æ‰°ã€‚æˆ‘ä»¬æå‡ºäº† Orionï¼Œè¿™æ˜¯ä¸€ä¸ªè½¯ä»¶ç³»ç»Ÿï¼Œå¯ä»¥é€æ˜Žåœ°æ‹¦æˆªæ¥è‡ªå…±äº« GPU çš„å¤šä¸ªå®¢æˆ·ç«¯çš„ GPU å†…æ ¸å¯åŠ¨ã€‚Orion ä»¥å„ä¸ªç®—å­çš„ç²’åº¦å®‰æŽ’ GPU ä¸Šçš„å·¥ä½œï¼Œå¹¶é€šè¿‡è€ƒè™‘æ¯ä¸ªç®—å­çš„è®¡ç®—å’Œå†…å­˜éœ€æ±‚æ¥æœ€å¤§é™åº¦åœ°å‡å°‘å¹²æ‰°ã€‚æˆ‘ä»¬å°† Orion é›†æˆåˆ° PyTorch ä¸­ï¼Œå¹¶åœ¨å„ç§ DNN å·¥ä½œè´Ÿè½½æ­é…ç”¨ä¾‹ä¸­å±•ç¤ºå…¶ä¼˜åŠ¿ã€‚Orion ä¸ºé«˜ä¼˜å…ˆçº§æŽ¨ç†ä½œä¸šä¿æŒä½Žå°¾éƒ¨å»¶è¿Ÿï¼ŒåŒæ—¶é…ç½®å°½åŠ›è€Œä¸ºçš„æŽ¨ç†ä½œä¸šï¼Œå°†æ¯ä¸ª GPU è¯·æ±‚åžåé‡æé«˜é«˜è¾¾ 7.3 å€ã€‚Orion åœ¨æ­é… DNN è®­ç»ƒæ—¶è¿˜ä¿æŒè¾ƒä½Žçš„æŽ¨ç†å»¶è¿Ÿï¼Œä¸Žä¸ºæ¯ä¸ªå·¥ä½œè´Ÿè½½ä½¿ç”¨ä¸“ç”¨ GPU ç›¸æ¯”ï¼Œå¯èŠ‚çœé«˜è¾¾ 1.49 å€çš„è®­ç»ƒæˆæœ¬ã€‚ä¸Žæœ€å…ˆè¿›çš„åŸºçº¿ç›¸æ¯”ï¼ŒOrion æ˜¾ç€æ”¹å–„äº†å°¾éƒ¨å»¶è¿Ÿã€‚

è¿™æ˜¯ä¸€ç§ GPU è°ƒåº¦å™¨ï¼Œç”¨äºŽæ‹¦æˆªæ¥è‡ªå…±äº« GPU çš„å¤šä¸ª DNN ä½œä¸šçš„æ“ä½œå‘˜ã€‚Orion æ ¹æ®æ“ä½œå‘˜çš„å¤§å°ã€è®¡ç®—ä¸Žå†…å­˜è¦æ±‚ä»¥åŠä½œä¸šä¼˜å…ˆçº§æ¥å®‰æŽ’æ“ä½œå‘˜ï¼Œä»¥ä¾¿å¯ä»¥å¹¶ç½®å…·æœ‰äº’è¡¥èµ„æºéœ€æ±‚çš„æ“ä½œå‘˜ã€‚

Orion ä¸ºé«˜ä¼˜å…ˆçº§ DNN ä½œä¸šä¿æŒé«˜æ€§èƒ½ï¼ˆä½Žå°¾éƒ¨å»¶è¿Ÿï¼‰ï¼ŒåŒæ—¶é€šè¿‡å¹¶ç½®å°½åŠ›è€Œä¸ºçš„ä½œä¸šæ¥æé«˜ GPU åˆ©ç”¨çŽ‡ã€‚Orion å°†è¿è¡Œ DNN å·¥ä½œè´Ÿè½½çš„æˆæœ¬é™ä½Žäº† 1.49 å€ï¼Œä¸Žä¸ºæ¯ä¸ªä½œä¸šä¸“ç”¨ä¸€ä¸ª GPU ç›¸æ¯”ã€‚ä¸Žä¹‹å‰çš„ GPU å…±äº«æŠ€æœ¯ç›¸æ¯”ï¼ŒOrion è¿˜æ”¹å–„äº†å°¾éƒ¨å»¶è¿Ÿã€‚

#### ä»‹ç»

They believe MPS  and GPU Stream æ˜¯ä¸å¤Ÿ interference-aware.  

å¹²æ‰°æ˜¯ä»€ä¹ˆå‘¢?  å°±æ˜¯æŠŠä¸¤ä¸ªmemory-intensiveçš„ BN2d kernels æ”¾åœ¨ä¸€ä¸ªSMä¸­. 

3.2

å¤§éƒ¨åˆ†GPU, preemptåŽä¸èƒ½æŠ¢å , æ‰€ä»¥æ˜¯æ€Žä¹ˆè°ƒåº¦çš„? å°±æ˜¯åœ¨torchä¸‹ä¸€å±‚,  hardware scheduler ä¸Šä¸€å±‚.

how they put in same SM?  you can allocate it by yourself?  MPS.  set a queue? 

###  5 orion

orionæ˜¯ä¸€ä¸ªa dynamically linked lib that controls GPU operations submitted by an application framework (e.g., PyTorch)

#### 5.1

```python
1 def run_scheduler ( client_q_hpé«˜ä¼˜å…ˆçº§ , client_q_be æœ€å¤§åŠªåŠ› ) :
2 be_duration = 0 , be_submitted = Event ()
3 hp_task_running = False
4 while True :
5 	op_hp = client_q_hp . pop ()
6 	op_be = client_q_be . peek () # å…ˆä¸åˆ é™¤. 
7 	if ( op_hp != None ) :
8 		launch_kernel ( op_hp , stream_hp ) # æœ‰é«˜é€‰é«˜
9 		hp_task_running = True
10 	if ( op_be != None ) :
11 		schedule = schedule_be ( op_hp , op_be )
12 if ( be_duration > DUR_THRESHOLD ) :
13 		if ( be_submitted . finished () ) :
14 	be_duration = 0
15 else :
16 schedule = False
17 if ( schedule ) :
18 client_q_be.pop ()
19 launch_kernel ( op_be , stream_be )
20 be_duration += op_be . duration
21 be_submitted . record ( stream_be )
22
23 def schedule_be ( op_hp , op_be ) :
24 		schedule = False
25 if (! hp_task_running ) :
26 		schedule = True
27 else if ( op_be . sm_needed < SM_THRESHOLD 
28 			and have_different_profiles ( op_hp , op_be ) ) :
29 schedule = True
30 return schedule
```

é˜ˆå€¼æ˜¯æ€Žä¹ˆç¡®å®šçš„?

SM_THRESHOLD  é»˜è®¤æ˜¯æ€»SMæ•°é‡,  å¦‚æžœhigh-priority jobæ˜¯training, SM_THRESHOLD å¯ä»¥å¾ˆå¤§. äºŒåˆ†æ³•è°ƒæ•´ SM_THRESHOLD. ä¸ºäº†é˜²æ­¢é«˜ä¼˜å…ˆçº§ job starve. 

 3000 lines of C++/CUDA code.



### DynaPipeï¼šé€šè¿‡åŠ¨æ€ç®¡é“ä¼˜åŒ–å¤šä»»åŠ¡è®­ç»ƒ

å¤šä»»åŠ¡æ¨¡åž‹è®­ç»ƒå·²è¢«é‡‡ç”¨æ¥å­¦ä¹ å•ä¸ªæ·±åº¦ç¥žç»ç½‘ç»œæ¨¡åž‹ï¼ˆé€šå¸¸æ˜¯å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼‰æ¥å¤„ç†å¤šä¸ªä»»åŠ¡ï¼ˆä¾‹å¦‚ï¼Œé—®ç­”å’Œæ–‡æœ¬æ‘˜è¦ï¼‰ã€‚ç”±äºŽä¸åŒä»»åŠ¡çš„ä¸Šä¸‹æ–‡ä¸åŒï¼Œå¤šä»»åŠ¡å­¦ä¹ é€šå¸¸æŽ¥æ”¶é•¿åº¦å·®å¼‚å¾ˆå¤§çš„è¾“å…¥åºåˆ—ã€‚é€šå¸¸é‡‡ç”¨å¡«å……ï¼ˆåˆ°ç›¸åŒçš„åºåˆ—é•¿åº¦ï¼‰æˆ–æ‰“åŒ…ï¼ˆå°†çŸ­ç¤ºä¾‹æ”¾å…¥ç›¸åŒé•¿åº¦çš„é•¿åºåˆ—ï¼‰æ¥å‡†å¤‡ç”¨äºŽæ¨¡åž‹è®­ç»ƒçš„è¾“å…¥æ ·æœ¬ï¼Œä½†è¿™åœ¨ç©ºé—´æˆ–è®¡ç®—æ•ˆçŽ‡ä¸Šä¸é«˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŠ¨æ€å¾®æ‰¹å¤„ç†æ–¹æ³•æ¥è§£å†³åºåˆ—é•¿åº¦å˜åŒ–å¹¶å®žçŽ°é«˜æ•ˆçš„å¤šä»»åŠ¡æ¨¡åž‹è®­ç»ƒã€‚æˆ‘ä»¬æå€¡ä½¿ç”¨å¯å˜é•¿åº¦å¾®æ‰¹æ¬¡å¯¹å¤§åž‹æ¨¡åž‹è¿›è¡Œç®¡é“å¹¶è¡Œè®­ç»ƒï¼Œæ¯ä¸ªå¾®æ‰¹æ¬¡å¯èƒ½åŒ…å«ä¸åŒæ•°é‡çš„æ ·æœ¬ã€‚æˆ‘ä»¬ä½¿ç”¨åŸºäºŽåŠ¨æ€ç¼–ç¨‹çš„æ–¹æ³•ä¼˜åŒ–å¾®æ‰¹é‡æž„å»ºï¼Œå¹¶é€šè¿‡åŠ¨æ€ç®¡é“å’Œé€šä¿¡è°ƒåº¦å¤„ç†å¾®æ‰¹é‡æ‰§è¡Œæ—¶é—´å˜åŒ–ï¼Œä»Žè€Œå®žçŽ°é«˜æ•ˆçš„ç®¡é“è®­ç»ƒã€‚å¯¹ FLANv2 æ•°æ®é›†çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜Žï¼Œä¸ŽåŸºäºŽæ‰“åŒ…çš„åŸºçº¿ç›¸æ¯”ï¼Œè®­ç»ƒ T5 æ—¶çš„è®­ç»ƒåžåé‡æé«˜äº† 4.39 å€ï¼Œè®­ç»ƒ GPT æé«˜äº† 3.25 å€ã€‚

æä¾›äº†awsæœåŠ¡å™¨

