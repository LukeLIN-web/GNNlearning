## Fundamental concepts of statistical learning

Uniform convergence (learning finite, realizable hypothesis spaces)

#### 迁移学习

- How does the difference between β(1) and β(2) affect transfer learning performance?   这个叫model shift.

- How does the difference between the feature vectors of source task and target task affect transfer learning?  这个叫 covariate shift

**Hard Transfer** assumes a single shared parameter vector (β\betaβ) for both tasks.

**Soft Transfer** allows separate parameters for each task but aligns them through regularization

Probably Approximately Correct Learning,  PAC learning

h：是一个理论上的候选假设，可能不一定是最佳的。

h^\hat：是通过训练优化得到的假设，用来对新数据进行预测。

Empirical Risk Minimization, ERM





## HW1











神经切线核